..:: Overall ::..
InStrain version 1.3.0g started at 2020-05-21 17:25:23 and ended at 2020-05-21 17:26:22.
Runtime = 59 seconds
Command = /Users/mattolm/miniconda3/bin/inStrain profile /Users/mattolm/Programs/inStrain/test/test_data/N5_271_010G1_scaffold_min1000.fa-vs-N5_271_010G1.sorted.bam /Users/mattolm/Programs/inStrain/test/test_data/N5_271_010G1_scaffold_min1000.fa -o /Users/mattolm/Programs/inStrain/test/test_backend/testdir/test -g /Users/mattolm/Programs/inStrain/test/test_data/N5_271_010G1_scaffold_min1000.fa.genes.fna --skip_plot_generation -p 6 -d

..:: Checkpoints ::..
filter_reads         took 3 seconds       (5.1% of overall)	RAM use increased by 75.70 MB
profile_scaffolds    took 33 seconds      (55.9% of overall)	RAM use increased by 96.30 MB
profile_genes        took 17 seconds      (28.8% of overall)	RAM use increased by - 2.48 MB
genome_wide          took 6 seconds       (10.2% of overall)	RAM use increased by - 5.00 MB

..:: Profile RAM useage and paralellization efficiency ::..
Wall time for Profile         	25 seconds
Total processes used (splits + merges)	12
Average number processes used 	4.1
Paralellization efficiency    	68.4%
Scaffolds profiled            	178

User time profiling splits    	1.0 minute, 15.0 seconds
Profile paralell efficiency   	63.4%
Average profile time per split	<1 second
Average time per split        	<1 second
Median time per split         	<1 second
Maximum split time            	7.0 seconds
Longest running split         	N5_271_010G1_scaffold_963.0
Per-process efficiency        	['49.1', '50.5', '51.6', '56.4', '74.6', '98.6']

User time merging splits      	28.0 seconds
Merge paralell efficiency     	88.9%
Average time per merge        	<1 second
Median time per merge         	<1 second
Maximum merge time            	<1 second
Longest running merge         	N5_271_010G1_scaffold_1
Per-process efficiency        	['88.0', '88.2', '88.3', '88.5', '89.8', '92.1']

System RAM available          	16.00 GB
Starting RAM usage (%)        	68.0%
Ending RAM usage (%)          	68.0%
Peak RAM used                 	10.91 GB
Mimimum RAM used              	10.77 GB

0 scaffolds needed to be run a second time

..:: Genes paralellization efficiency ::..
calculate_gene_metrics took 13.0 seconds    (100.0% of overall)	RAM use increased by 23.63 MB
make_globals         took 2.0 seconds     (15.4% of overall)	RAM use increased by 19.98 MB
create_queue         took <1 second       (0.0% of overall)	RAM use increased by 212.00 KB
return_results       took <1 second       (0.0% of overall)	RAM use increased by 90.07 MB

Wall time parallelized steps  	10 seconds
Total processes used          	6
Average number processes used 	5.2
Paralellization efficiency    	87.3%
Scaffolds profiled            	173
Average time per scaffold     	<1 second
Median time per scaffold      	<1 second
Maximum split scaffold        	6.0 seconds
Longest running scaffold      	N5_271_010G1_scaffold_2
Per-process efficiency        	['100.0', '62.1', '74.2', '93.2', '95.8', '99.0']
Step SNP_character:           	7.1% of parallel runtime
Step SNP_counts:              	71.2% of parallel runtime
Step SNP_counts_SiteCalc:     	1.7% of parallel runtime
Step SNP_counts_geneCalc:     	68.2% of parallel runtime
Step clonality:               	10.2% of parallel runtime
Step coverage:                	11.1% of parallel runtime

..:: Geneome level report ::..
genomeLevel_from_IS  took 3.0 seconds     (100.0% of overall)	RAM use increased by 1.14 MB
scaffold_info        took <1 second       (0.0% of overall)	RAM use increased by 164.00 KB
coverage_info        took 2.0 seconds     (66.7% of overall)	RAM use decreased by 14.31 MB
mapping_info         took <1 second       (0.0% of overall)	RAM use decreased by 0.0 Byte
linkage              took <1 second       (0.0% of overall)	RAM use increased by 64.00 KB


..:: Plotting ::..

..:: Failures ::..
No failures
